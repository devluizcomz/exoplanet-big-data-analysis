# ğŸŒ Exoplanet Big Data Analysis: Hunting for Earth 2.0

![Python](https://img.shields.io/badge/python-v3.10+-blue.svg)
![Hadoop](https://img.shields.io/badge/hadoop-v3.3-yellow.svg)
![Spark](https://img.shields.io/badge/spark-v3.5-orange.svg)
![Hive](https://img.shields.io/badge/hive-v3.1-green.svg)
![Docker](https://img.shields.io/badge/docker-containerized-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

> **AnÃ¡lise de 5,759 exoplanetas do NASA Exoplanet Archive usando Apache Hadoop, Spark e Hive para identificar candidatos habitÃ¡veis Ã  "Terra 2.0"**

## ğŸ“Š RelatÃ³rio Interativo
ğŸš€ **[Ver AnÃ¡lise Completa (RelatÃ³rio HTML)](https://fmlwhgoa.gensparkspace.com/)**

## ğŸ¯ Principais Descobertas

- **5,759 exoplanetas** analisados do NASA Exoplanet Archive
- **65 candidatos habitÃ¡veis** identificados (1.13% do dataset)
- **3 planetas com score perfeito** de habitabilidade (4.0/4.0)
- **Kepler-442 b** como melhor candidato a "Terra 2.0"
- **71.4% das descobertas** usam mÃ©todo Transit

## ğŸ† Top 3 Candidatos a Terra 2.0

| PosiÃ§Ã£o | Planeta | Score | Raio (Ã—Terra) | Temperatura | DistÃ¢ncia |
|---------|---------|-------|---------------|-------------|-----------|
| ğŸ¥‡ | **Kepler-442 b** | 4.0/4.0 | 1.34Ã— | 233 K (-40Â°C) | 1,206 anos-luz |
| ğŸ¥ˆ | Kepler-62 f | 4.0/4.0 | 1.41Ã— | 208 K (-65Â°C) | 1,200 anos-luz |
| ğŸ¥‰ | Kepler-186 f | 4.0/4.0 | 1.17Ã— | 188 K (-85Â°C) | 580 anos-luz |

## ğŸ› ï¸ Stack TecnolÃ³gico

### Core Technologies
- **Apache Hadoop 3.3** - Distributed storage (HDFS)
- **Apache Spark 3.5** - Distributed processing (PySpark)
- **Apache Hive 3.1** - Data warehouse and SQL queries
- **Python 3.10** - Data processing and analysis
- **Docker** - Containerized environment

### Data Formats & Tools
- **Parquet** - Columnar storage format
- **PostgreSQL** - Hive Metastore
- **Jupyter Notebooks** - Interactive analysis
- **Matplotlib/Seaborn** - Data visualizations

## ğŸ—ï¸ Arquitetura do Sistema

```
NASA Exoplanet Archive API
          â†“
    [Raw Data Ingestion]
          â†“
      HDFS Storage
          â†“
    Spark Processing
    (Feature Engineering)
          â†“
    Parquet Files (HDFS)
          â†“
    Hive External Tables
          â†“
   Analysis & Insights
```

## ğŸ“ Estrutura do Projeto

```
exoplanet-big-data-analysis/
â”œâ”€â”€ README.md                          # Este arquivo
â”œâ”€â”€ docker/                           # Docker setup
â”‚   â”œâ”€â”€ docker-compose.yml           # OrquestraÃ§Ã£o de serviÃ§os
â”‚   â”œâ”€â”€ hadoop.env                   # ConfiguraÃ§Ãµes Hadoop
â”‚   â””â”€â”€ README.md                    # DocumentaÃ§Ã£o Docker
â”œâ”€â”€ scripts/                         # Scripts de processamento
â”‚   â”œâ”€â”€ 01_download_data.py          # Download dos dados
â”‚   â”œâ”€â”€ 02_spark_analysis.py         # Processamento Spark
â”‚   â”œâ”€â”€ 03_generate_insights.py      # GeraÃ§Ã£o de insights
â”‚   â””â”€â”€ 04_create_visualizations.py  # CriaÃ§Ã£o de grÃ¡ficos
â”œâ”€â”€ sql/                             # Scripts SQL
â”‚   â”œâ”€â”€ create_tables.sql            # DDL Hive
â”‚   â””â”€â”€ analysis_queries.sql         # Consultas analÃ­ticas
â”œâ”€â”€ data/                            # Dados do projeto
â”‚   â”œâ”€â”€ raw/                         # Dados brutos
â”‚   â”‚   â””â”€â”€ exoplanets_raw.csv       # Dataset NASA
â”‚   â””â”€â”€ processed/                   # Dados processados
â”‚       â”œâ”€â”€ planets_enriched/        # Planetas com features
â”‚       â”œâ”€â”€ earth_candidates/        # Candidatos habitÃ¡veis
â”‚       â”œâ”€â”€ discovery_stats/         # Stats por mÃ©todo
â”‚       â””â”€â”€ category_stats/          # Stats por categoria
â”œâ”€â”€ docs/                            # DocumentaÃ§Ã£o
â”‚   â”œâ”€â”€ insights.md                  # Insights detalhados
â”‚   â”œâ”€â”€ architecture.md              # Arquitetura tÃ©cnica
â”‚   â””â”€â”€ data-dictionary.md           # DicionÃ¡rio de dados
â”œâ”€â”€ visualizations/                  # GrÃ¡ficos gerados
â”‚   â”œâ”€â”€ 01_discovery_methods.png     # MÃ©todos descoberta
â”‚   â”œâ”€â”€ 02_planet_categories.png     # Categorias planetas
â”‚   â”œâ”€â”€ 03_top5_candidates.png       # Top 5 candidatos
â”‚   â”œâ”€â”€ 04_general_stats.png         # Dashboard estatÃ­sticas
â”‚   â”œâ”€â”€ 05_earth_comparison.png      # ComparaÃ§Ã£o Terra
â”‚   â””â”€â”€ 06_journey_infographic.png   # InfogrÃ¡fico jornada
â””â”€â”€ venv/                            # Python virtual environment
```

## ğŸš€ Como Executar o Projeto

### 1. PrÃ©-requisitos
```bash
# Instalar Docker e Docker Compose
docker --version
docker-compose --version

# Instalar Python 3.10+
python --version
```

### 2. Clonar o RepositÃ³rio
```bash
git clone https://github.com/yourusername/exoplanet-big-data-analysis.git
cd exoplanet-big-data-analysis
```

### 3. Setup do Ambiente Python
```bash
# Criar ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate   # Windows

# Instalar dependÃªncias
pip install requests pandas matplotlib seaborn jupyter pyspark
```

### 4. Iniciar Stack Big Data
```bash
cd docker
docker-compose up -d

# Verificar serviÃ§os
docker-compose ps
```

### 5. Executar Pipeline de Dados
```bash
# 1. Download dos dados
python scripts/01_download_data.py

# 2. Processamento Spark
docker exec -it spark-master /spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  /app/scripts/02_spark_analysis.py

# 3. Gerar insights
docker exec -it spark-master /spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  /app/scripts/03_generate_insights.py

# 4. Criar visualizaÃ§Ãµes
python scripts/04_create_visualizations.py
```

### 6. Acessar Interfaces Web
- **Hadoop NameNode:** http://localhost:9870
- **Spark Master:** http://localhost:8080
- **Hive Server:** http://localhost:10002

## ğŸ”¬ Metodologia

### Habitability Score (0-4 pontos)
Desenvolvi um score customizado baseado em 4 critÃ©rios:

| CritÃ©rio | Pontos | Range | DescriÃ§Ã£o |
|----------|--------|-------|-----------|
| Tamanho do Planeta | +1 | 0.5-2Ã— Terra | Similar ao tamanho da Terra |
| Temperatura | +1 | 200-350 K | Faixa adequada para Ã¡gua lÃ­quida |
| Tipo de Estrela | +1 | 4500-7000 K | Estrela hospedeira tipo Sol |
| DistÃ¢ncia da Terra | +1 | <500 parsecs | Relativamente prÃ³ximo |

### Feature Engineering
```python
# Exemplo de cÃ¡lculo do score
def calculate_habitability_score(planet):
    score = 0
    if 0.5 <= planet.radius <= 2.0: score += 1      # Tamanho
    if 200 <= planet.temperature <= 350: score += 1  # Temperatura  
    if 4500 <= planet.star_temp <= 7000: score += 1 # Estrela
    if planet.distance < 500: score += 1            # DistÃ¢ncia
    return score
```

## ğŸ“ˆ Performance

- **Processamento:** ~5,759 exoplanetas em **segundos** (Spark in-memory)
- **Storage:** Dados comprimidos em formato Parquet (eficiÃªncia de armazenamento)
- **Escalabilidade:** Arquitetura preparada para datasets 100x maiores

## ğŸ“– DocumentaÃ§Ã£o Adicional

- ğŸ“Š **[Insights Detalhados](docs/insights.md)** - AnÃ¡lises aprofundadas e descobertas
- ğŸ—ï¸ **[Arquitetura TÃ©cnica](docs/architecture.md)** - Detalhes da implementaÃ§Ã£o
- ğŸ“š **[DicionÃ¡rio de Dados](docs/data-dictionary.md)** - DescriÃ§Ã£o das variÃ¡veis

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:
1. FaÃ§a fork do projeto
2. Crie sua feature branch (`git checkout -b feature/nova-analise`)
3. Commit suas mudanÃ§as (`git commit -am 'Adiciona nova anÃ¡lise'`)
4. Push para a branch (`git push origin feature/nova-analise`)
5. Crie um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ“ Contato

**Luiz [Seu Sobrenome]** - [Seu Email]
- ğŸ’¼ LinkedIn: [Seu LinkedIn]
- ğŸ± GitHub: [Seu GitHub]
- ğŸŒ Portfolio: [Seu Site]

## ğŸ™ Agradecimentos

- ğŸŒŒ **NASA Exoplanet Archive** - Pelos dados pÃºblicos
- ğŸš€ **Apache Foundation** - Pelas ferramentas open source (Hadoop, Spark, Hive)
- ğŸ³ **Docker Community** - Pela containerizaÃ§Ã£o simplificada
- ğŸ‘¥ **Cloudera/Hortonworks** - Pela documentaÃ§Ã£o e melhores prÃ¡ticas

---

â­ **Se este projeto foi Ãºtil, considere dar uma estrela!** â­

**ğŸŒ A busca por vida continua... e Big Data estÃ¡ acelerando nossas descobertas!** ğŸš€